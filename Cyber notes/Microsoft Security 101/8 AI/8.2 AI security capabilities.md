- **Counterfit**: open-source automation tool for AI systems security testing, AI security risk assessments, ensures robustness of algorithms
- **Adversarial Machine Learning Tools**: evaluate robustness of machine learning models against adversarial attacks, identify, mitigate vulnerabilities
- **AI Security Toolkits**: open-source, provide resources for securing AI systems (libraries, frameworks for implementing security measures)
- **Collaborative Platforms**: partnerships between companies and AI communities develop AI-specific security scanners and other tools to secure AI supply chain
#### AI red teaming
| Aspect                        | AI                                            | Traditional                                                      |
| ----------------------------- | --------------------------------------------- | ---------------------------------------------------------------- |
| **Target Focus**              | AI specific vulnerabilities (models, data)    | Traditional IT infrastructure                                    |
| **Testing Target**            | AI responses to unusual or unexpected inputs  | System responses to security threats                             |
| **Failure Exploration**       | Malicious and benign AI failures              | Focus primarily on security breaches                             |
| **Content Vulnerabilities**   | Prompt injection, harmful content generation  | Typically no content generation vulnerabilities                  |
| **Ethics and Responsibility** | AI robustness, responsible behavior by design | Focus on security without necessarily addressing ethical aspects |
